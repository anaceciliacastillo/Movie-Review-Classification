{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYyCooK6gs2H",
        "outputId": "41a6cc71-edfa-497b-884a-5402017535dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyprind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8JR9ENJgyAO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyprind\n",
        "import pprint\n",
        "from sklearn.datasets import make_classification\n",
        "import pickle\n",
        "import os\n",
        "import re\n",
        "import sqlite3\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtRbHwT-g0o7",
        "outputId": "a5832ebc-b553-46c5-83cb-db15d9b77061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if '/content/drive' not in os.listdir('/content'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVnsU1gDg89r"
      },
      "outputs": [],
      "source": [
        "basepath = '/content/drive/My Drive/SentimentClassification/aclImdb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U40ULW_RhSvx",
        "outputId": "abc5f3fa-ef66-4d70-9db4-e15754f0c99a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0% [##                            ] 100% | ETA: 02:05:23"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              review  sentiment\n",
            "0  Once again Mr. Costner has dragged out a movie...          0\n",
            "1  First of all, I would like to say that I am a ...          0\n",
            "2  I'm a huge fan of both Emily Watson (Breaking ...          0\n",
            "3  I was pulled into this movie early on, much to...          0\n",
            "4  This tale of the upper-classes getting their c...          0\n"
          ]
        }
      ],
      "source": [
        "labels = {'pos': 1, 'neg': 0}\n",
        "pbar = pyprind.ProgBar(50000)  # Adjust this number if necessary based on the number of reviews\n",
        "df_list = []  # List to store data temporarily\n",
        "\n",
        "# Process the dataset\n",
        "for s in ('test', 'train'):\n",
        "    for l in ('pos', 'neg'):\n",
        "        path = os.path.join(basepath, s, l)\n",
        "        for file in sorted(os.listdir(path)):\n",
        "            with open(os.path.join(path, file), 'r', encoding='utf-8') as infile:\n",
        "                txt = infile.read()\n",
        "                df_list.append([txt, labels[l]])\n",
        "                pbar.update()\n",
        "\n",
        "df = pd.DataFrame(df_list, columns=['review', 'sentiment'])\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydidCdj5i_aK"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv('movie_data.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "K0IgAIkmjr7Y",
        "outputId": "20ebe6d8-4ad4-4f47-e6f5-03b3e215773c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4965,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4915,\n        \"samples\": [\n          \"If you read the book before seeing the movie you may be disappointed like I was. The book was great and I was sure after seeing the movie preview that the movie would be great as well, however I felt like I was watching a movie where the director and cast did not even read what these characters where like. The movie is short and they do not really ever make us feel that these people were truly in love and felt like sole mates. Even if the movie did not go in the same direction as the book at least they could of made the romance between these two characters feel more intense. I think both Diane Lane and Richard Gere were perfect for these two characters and they have good chemistry however they just did not develop a long enough storyline for us to see how they longed for each other. The book was true love story and I think this movie could of been a lot better.\",\n          \"B. Kennedy tried to make a sequel by exaggerating and amplifying\\u0097a gargantuan leftist western (not as leftist as the G. Kennedy sequel, that came after this one).<br /><br />This is the ugliest film of the two sequels\\u0097very ugly looking. It is slapdash. B. Kennedy made it amplifying\\u0097but without having the genius for that. Hundreds of peons, hundreds of Mexican _compadres, hundreds of women, a desert, barren landscapes, a storm\\u0097the largest scale.<br /><br />Everything in this clumsy sequel, likable only in a weird way, is phony.<br /><br />The movie itself is very ugly looking. Brynner, who made the best part in the first film, doesn't look good at all in this one.<br /><br />Rey plays a priest; he will be a political leader, Quintero, in the next sequel of the franchise. <br /><br />It is true that when you have that many characters you may not need a very interesting storyline; sometimes. E.g., Brynner meets McQueen; then they pick other 'compadres'; or, B. Spencer meets Coburn; etc.. It's fun to see where and how they'll meet the rest of the crew, etc.. But you need at least these several characters. Unfortunately, Burt Kennedy's installment is not very good at that. <br /><br />Return of the Seven (1966) begins with a bullfighting. Vin and Chris meet there; they decide to rescue the third survivor of the original Magnificents\\u0097Chico, who belongs to a huge group of 300 peons abducted by the Mexican bandits. We find out the name of Chico's appealing wife\\u0097it's Petra. Chris must constitute again a small army\\u0097and here we have a Dirty Dozen treat\\u0097Chris chooses his men from the convicts. Another member of the commando is a womanizer, who will take good care of the wives left without husbands. The sexual humor is especially displeasing and distasteful in this film. It strives to seem smart and spicy; it is simply boorish and dumb and gross.<br /><br />The choosing of the members of the small army was one of the greatest joys in the McQueen film. Unfortunately, in the first sequel there is the most unmemorable of the three crews assembled under the Magnificent Seven's name.<br /><br />Robert Fuller makes a lousy \\\"Vin\\\";Oates is the smiley womanizer.<br /><br />In this mock\\u0097gargantuan attempt, a Mexican revolutionary leader has a gargantuan plan\\u0097he kidnaps 300 peons and uses them to build a village and a church in the memory of his lost sons. (Useless to say that this insane Mexican revolutionist doesn't equal Wallach's part in the first film.) B. Kennedy bets exclusively on camp and over\\u0097the\\u0097top stuff: ugly landscapes, a thunderstorm, gargantuan lightning ,a desert. A huge battle between the emancipated peons and the revolutionary vaqueros. Of course Return of the Seven (1966) completely abandoned the good sense of the McQueen film.<br /><br />What is particularly shocking is that this sequel came quite quickly after the original film\\u0097yet, everything changed meantime in the way of making westerns.<br /><br />Both the sequels look weird.\",\n          \"Okay, it was very good...but Best Picture? Please, not even close. Munich was better, Capote was much better, Good Night and Good Luck was much better...Brokeback Mountain - well, that should have won! The Academy voters seem to act like the current day Democrats - please just a little of everyone, but don't dare take any concrete positions. That's why we have a complete moron in office in the US.<br /><br />This has been the WORST AA presentation ... and forget 1987 ... since way before that. Hollywood is so afraid of it's bottom line, that it can't be set \\\"straight\\\". Many voters apparently didn't even see Brokeback Mountain. Get real and get with it.<br /><br />This was the most pathetic year since I have been watching in the mid- 60's and I was only two.<br /><br />Wake up, whoever you are. Hollywood IS mainstream, and that's what happened to the Box Office in 2005. King Kong, the last Star Wars film, another Batman film, a re-make or whatever of Charlie and The Chocolate Factory, and much more to come in 2006.<br /><br />At least there were original best pictures, i.e. Munich, but heard that one before, Capote - great; Katherine Keener should have won, even though now we know Reese can sing like a Cash/Carter, etc., Syriana was a much better picture than Crash. That film has been done, since the early 1960's and we have to make that the best film? What a horrible Oscar night and a horrible year to end with in 2005 and another boring year in 2006. At least the BAFTA for best picture went to Brokeback, and what about the horrible song that won? Pathetic. I think we only have about 20 years left as America or the USA, before someone comes in and changes up things a bit. Maybe it will be China since they own so much of this country ... or India, because they have all the high-tech jobs and are the largest democratic country in the entire world.<br /><br />America has become the land of the fat, the pathetic, and the stupid. Trash can be found in more places than Florida, West Virgina, South Dakota, and in the mid-West.<br /><br />Drive-through a local McDonald's or Burger King for goodness sake. Order all you want until you get a heart attack. Put yourself out of your misery.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-81aaf60a-2a76-4e1f-a9a8-ba1272c73e5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I saw this on sale - NEW - at my local store f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>and it's only January, still I'm sure of it!&lt;b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This movie is so unreal. French movies like th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81aaf60a-2a76-4e1f-a9a8-ba1272c73e5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81aaf60a-2a76-4e1f-a9a8-ba1272c73e5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81aaf60a-2a76-4e1f-a9a8-ba1272c73e5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a2b087f4-d1c7-4db6-acf8-aa460029f67f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2b087f4-d1c7-4db6-acf8-aa460029f67f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a2b087f4-d1c7-4db6-acf8-aa460029f67f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  I saw this on sale - NEW - at my local store f...          0\n",
              "1  and it's only January, still I'm sure of it!<b...          0\n",
              "2  This movie is so unreal. French movies like th...          0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PTXHeTjkEgp",
        "outputId": "46231f4e-9412-49f4-f2ce-fcd0d00bc138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape\n",
        "(50000, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSbWZB9rkPLe",
        "outputId": "b991ed9a-9c3f-4166-dfc6-a3b14a1de5f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary:\n",
            "{   'and': 0,\n",
            "    'is': 1,\n",
            "    'one': 2,\n",
            "    'shining': 3,\n",
            "    'sun': 4,\n",
            "    'sweet': 5,\n",
            "    'the': 6,\n",
            "    'two': 7,\n",
            "    'weather': 8}\n",
            "Feature vectors:\n",
            "[[0 1 0 1 1 0 1 0 0]\n",
            " [0 1 0 0 0 1 1 0 1]\n",
            " [2 3 2 1 1 1 2 1 1]]\n"
          ]
        }
      ],
      "source": [
        "docs = np.array([\n",
        "    'The sun is shining',\n",
        "    'The weather is sweet',\n",
        "    'The sun is shining, the weather is sweet, and one and one is two'\n",
        "])\n",
        "\n",
        "count = CountVectorizer()\n",
        "\n",
        "bag = count.fit_transform(docs)\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4) # for better formatting\n",
        "\n",
        "print(\"Vocabulary:\")\n",
        "pp.pprint(count.vocabulary_)\n",
        "\n",
        "print(\"Feature vectors:\")\n",
        "print(bag.toarray())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3QOmoNcrIWm",
        "outputId": "76410f4c-ea36-436c-bb82-4795f0d61a09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ]\n",
            " [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56]\n",
            " [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]\n"
          ]
        }
      ],
      "source": [
        "tfidf = TfidfTransformer(use_idf=True,\n",
        "                         norm='l2',\n",
        "                         smooth_idf=True)\n",
        "np.set_printoptions(precision=2)\n",
        "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PMCtYXBBsHl2",
        "outputId": "aec10a05-6239-4a6a-9515-a6647210d370"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'is seven.<br /><br />Title (Brazil): Not Available'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " df.loc[0, 'review'][-50:]\n",
        "'is seven.<br /><br />Title (Brazil): Not Available'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOrncMx0tdv2",
        "outputId": "7e61cff9-b2b1-4a39-a685-32a559162a22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed last 50 characters of the first review:\n",
            "ironheart is so bad it ain t even funny it s sad  \n",
            "Processed example text:\n",
            "this is a test  :) :( :)\n"
          ]
        }
      ],
      "source": [
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "\n",
        "    # Remove all non-word characters and convert text to lowercase, then append emoticons to end\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', '')\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply the preprocessing function to all reviews in the DataFrame\n",
        "df['review'] = df['review'].apply(preprocessor)\n",
        "\n",
        "# Example of how to test the function on the last 50 characters of the first document\n",
        "print(\"Processed last 50 characters of the first review:\")\n",
        "print(preprocessor(df.loc[0, 'review'][-50:]))\n",
        "\n",
        "# Directly testing the preprocessor with sample text\n",
        "print(\"Processed example text:\")\n",
        "print(preprocessor(\"</a>This :) is :( a test :-)!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQEpgwSLx04D",
        "outputId": "698ec696-f7f6-4342-d51c-fdbf0a5d627b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4voXBVTyMYl",
        "outputId": "ea2bdd7e-63d6-4f96-f139-717c2ddba667"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized: ['runners', 'like', 'running', 'and', 'thus', 'they', 'run']\n",
            "Stemmed: ['runner', 'like', 'run', 'and', 'thu', 'they', 'run']\n",
            "Filtered (stop-words removed): ['runner', 'like', 'run', 'thu', 'run']\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "# Tokenizer and Stemmer\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "\n",
        "# Stop-words\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Example usage of the tokenizer and stemmer\n",
        "text = 'runners like running and thus they run'\n",
        "print(\"Tokenized:\", tokenizer(text))\n",
        "print(\"Stemmed:\", tokenizer_porter(text))\n",
        "\n",
        "# Example for removing stop-words\n",
        "stemmed_tokens = tokenizer_porter(text)\n",
        "filtered_tokens = [word for word in stemmed_tokens if word not in stop]\n",
        "print(\"Filtered (stop-words removed):\", filtered_tokens)\n",
        "\n",
        "# Applying these preprocessing steps to the DataFrame\n",
        "# Assuming 'df' is your DataFrame and 'review' is the column containing text data\n",
        "df['review'] = df['review'].apply(lambda x: ' '.join(tokenizer_porter(x)))\n",
        "df['review'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMqXlaRwzWOU",
        "outputId": "ea9a7f70-5b33-4a28-ceea-08ad116b28cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n    raise ValueError(\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-e2ef5378cfb4>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Fitting the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mgs_lr_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Best parameter set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n    raise ValueError(\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n"
          ]
        }
      ],
      "source": [
        "stop = stopwords.words('english')\n",
        "\n",
        "# Data division\n",
        "X_train = df.loc[:25000, 'review'].values\n",
        "y_train = df.loc[:25000, 'sentiment'].values\n",
        "X_test = df.loc[25000:, 'review'].values\n",
        "y_test = df.loc[25000:, 'sentiment'].values\n",
        "\n",
        "# Define a TfidfVectorizer with potential parameters for GridSearch\n",
        "tfidf = TfidfVectorizer(strip_accents=None,\n",
        "                        lowercase=False,\n",
        "                        preprocessor=None)\n",
        "\n",
        "# Parameter grid for GridSearch\n",
        "param_grid = [\n",
        "    {'vect__ngram_range': [(1, 1)],\n",
        "     'vect__stop_words': [stop, None],\n",
        "     'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "     'clf__penalty': ['l1', 'l2'],\n",
        "     'clf__C': [1.0, 10.0, 100.0]},\n",
        "    {'vect__ngram_range': [(1, 1)],\n",
        "     'vect__stop_words': [stop, None],\n",
        "     'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "     'vect__use_idf': [False],\n",
        "     'vect__norm': [None],\n",
        "     'clf__penalty': ['l1', 'l2'],\n",
        "     'clf__C': [1.0, 10.0, 100.0]}\n",
        "]\n",
        "\n",
        "# Pipeline setup with TfidfVectorizer and LogisticRegression\n",
        "lr_tfidf = Pipeline([\n",
        "    ('vect', tfidf),\n",
        "    ('clf', LogisticRegression(random_state=0, solver='liblinear'))\n",
        "])\n",
        "\n",
        "# GridSearchCV setup\n",
        "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=5, verbose=2,\n",
        "                           n_jobs=-1)  # use n_jobs=-1 to use all cores\n",
        "\n",
        "# Fitting the model\n",
        "gs_lr_tfidf.fit(X_train, y_train)\n",
        "\n",
        "# Best parameter set\n",
        "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n",
        "\n",
        "# Checking performance on the training and test set\n",
        "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)\n",
        "clf = gs_lr_tfidf.best_estimator_\n",
        "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jSdoVnwaKT8",
        "outputId": "b0f3de68-2263-49e5-b363-db2d6253bc30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 1:\n",
            "book read completely train heart\n",
            "Topic 2:\n",
            "series space vampire dracula earth\n",
            "Topic 3:\n",
            "jack killer book scarlett high\n",
            "Topic 4:\n",
            "stupid american main shows children\n",
            "Topic 5:\n",
            "comedy jokes series original family\n",
            "Topic 6:\n",
            "stupid girl snakes woman girls\n",
            "Topic 7:\n",
            "performance action production version audience\n",
            "Topic 8:\n",
            "young house girl goes woman\n",
            "Topic 9:\n",
            "effects special budget terrible ed\n",
            "Topic 10:\n",
            "alien action waste horrible predator\n",
            "\n",
            "Review #79:\n",
            "Through its 2-hour running length, Crash charts the emotional anguish of its 10-odd ensemble of characters when faced with the sometimes blatant and sometimes latent forms of racism underlying in American society. That and the emotional anguish of one of its audiences sitting near the front and desp\n",
            "\n",
            "Review #2600:\n",
            "Ill-conceived sequel(..the absurd idea of having the killer snowman on the rampage at an island resort where there is no snow or cold weather)brings back the spirit of the psychopath, returning thanks to a scientific experiment providing foreign elements which reintroduce life to his molecules(..it'\n",
            "\n",
            "Review #2107:\n",
            "Ill-conceived sequel(..the absurd idea of having the killer snowman on the rampage at an island resort where there is no snow or cold weather)brings back the spirit of the psychopath, returning thanks to a scientific experiment providing foreign elements which reintroduce life to his molecules(..it'\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
        "\n",
        "# Define the tokenizer function with stop-word removal\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = [w for w in text.split() if w not in stop_words]\n",
        "    return tokenized\n",
        "\n",
        "# Feature Extraction: Transform the text data into a bag-of-words model\n",
        "count = CountVectorizer(stop_words='english', tokenizer=tokenizer, max_df=0.1, max_features=5000)\n",
        "X = count.fit_transform(df['review'].values)\n",
        "\n",
        "# LDA Model\n",
        "lda = LatentDirichletAllocation(n_components=10, random_state=123, learning_method='batch')\n",
        "X_topics = lda.fit_transform(X)\n",
        "\n",
        "# Display the top words for each topic\n",
        "n_top_words = 5\n",
        "feature_names = count.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f\"Topic {topic_idx + 1}:\")\n",
        "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
        "\n",
        "# To print out example reviews from one topic category\n",
        "def print_reviews_for_topic(topic_idx, n_reviews):\n",
        "    # Select reviews indices for the specified topic\n",
        "    reviews_idx = np.argsort(X_topics[:, topic_idx])[::-1]\n",
        "    for i in reviews_idx[:n_reviews]:\n",
        "        print(f\"\\nReview #{i}:\")\n",
        "        print(df.iloc[i, 0][:300])  # print the first 300 characters of the review\n",
        "\n",
        "# Example: print three reviews from the topic that relates to horror movies (assuming it's topic #6)\n",
        "print_reviews_for_topic(6 - 1, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ah-C6l6zCe0",
        "outputId": "1d87e2d5-057f-4b91-e11d-d0d4759630a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Horror movie #1:\n",
            "Through its 2-hour running length, Crash charts the emotional anguish of its 10-odd ensemble of characters when faced with the sometimes blatant and sometimes latent forms of racism underlying in American society. That and the emotional anguish of one of its audiences sitting near the front and desp ...\n",
            "\n",
            "Horror movie #2:\n",
            "Ill-conceived sequel(..the absurd idea of having the killer snowman on the rampage at an island resort where there is no snow or cold weather)brings back the spirit of the psychopath, returning thanks to a scientific experiment providing foreign elements which reintroduce life to his molecules(..it' ...\n",
            "\n",
            "Horror movie #3:\n",
            "Ill-conceived sequel(..the absurd idea of having the killer snowman on the rampage at an island resort where there is no snow or cold weather)brings back the spirit of the psychopath, returning thanks to a scientific experiment providing foreign elements which reintroduce life to his molecules(..it' ...\n"
          ]
        }
      ],
      "source": [
        "horror = X_topics[:, 5].argsort()[::-1]\n",
        "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
        "  print('\\nHorror movie #%d:' % (iter_idx + 1))\n",
        "  print(df['review'][movie_idx][:300], '...')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}